{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŒ Geospatial Image Segmentation Training on Google Colab T4 GPU\n",
        "\n",
        "This notebook trains a dual-input U-Net model for geospatial image segmentation using the complete dataset.\n",
        "\n",
        "**Features:**\n",
        "- Optimized for Google Colab T4 GPU\n",
        "- Full dataset training (2968 train + 1694 test images)\n",
        "- Advanced data augmentation\n",
        "- Mixed precision training\n",
        "- Model checkpointing with Google Drive integration\n",
        "- Real-time training visualization\n",
        "- Comprehensive metrics tracking\n",
        "\n",
        "**Dataset Structure:**\n",
        "- Dual input images: `im1/` and `im2/`\n",
        "- Dual output labels: `label1/` and `label2/`\n",
        "- 3-class segmentation: Background (0), Class 1 (128â†’1), Class 2 (255â†’2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Setup and Environment Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability and type\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "print(\"ðŸ” System Information:\")\n",
        "print(f\"Python version: {subprocess.check_output(['python', '--version']).decode().strip()}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"âš ï¸ CUDA not available. Please enable GPU in Runtime > Change runtime type\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nðŸŽ¯ Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"Pillow\", \"numpy\", \"matplotlib\", \"scikit-learn\", \"tqdm\", \"pyyaml\"])\n",
        "\n",
        "print(\"âœ… Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive for data storage and model saving\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories for outputs\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/geospatial_segmentation', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/geospatial_segmentation/models', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/geospatial_segmentation/logs', exist_ok=True)\n",
        "\n",
        "print(\"âœ… Google Drive mounted and directories created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Data Upload and Preparation\n",
        "\n",
        "**Instructions:**\n",
        "1. Zip your dataset folder containing `train/` and `test/` directories\n",
        "2. Upload the zip file using the file browser on the left\n",
        "3. Run the cell below to extract and verify the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload and extract dataset\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Option 1: Upload zip file\n",
        "print(\"ðŸ“¤ Upload your dataset zip file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the uploaded file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"ðŸ“¦ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "        print(\"âœ… Dataset extracted successfully!\")\n",
        "        break\n",
        "\n",
        "# Verify dataset structure\n",
        "required_dirs = [\n",
        "    '/content/train/im1', '/content/train/im2', \n",
        "    '/content/train/label1', '/content/train/label2',\n",
        "    '/content/test/im1', '/content/test/im2', \n",
        "    '/content/test/label1', '/content/test/label2'\n",
        "]\n",
        "\n",
        "print(\"\\nðŸ” Verifying dataset structure:\")\n",
        "for dir_path in required_dirs:\n",
        "    if os.path.exists(dir_path):\n",
        "        count = len([f for f in os.listdir(dir_path) if f.endswith('.png')])\n",
        "        print(f\"âœ… {dir_path}: {count} images\")\n",
        "    else:\n",
        "        print(f\"âŒ {dir_path}: NOT FOUND\")\n",
        "\n",
        "# Count total images\n",
        "train_count = len([f for f in os.listdir('/content/train/im1') if f.endswith('.png')])\n",
        "test_count = len([f for f in os.listdir('/content/test/im1') if f.endswith('.png')])\n",
        "print(f\"\\nðŸ“Š Dataset Summary:\")\n",
        "print(f\"Training images: {train_count}\")\n",
        "print(f\"Test images: {test_count}\")\n",
        "print(f\"Total images: {train_count + test_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  Model Architecture and Training Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import jaccard_score, f1_score\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"âœ… Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset class and Model Architecture (condensed version)\n",
        "class DualInputDataset(Dataset):\n",
        "    def __init__(self, data_dir, image_files, transform=None, augment_transform=None, is_train=True):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_files = image_files\n",
        "        self.transform = transform\n",
        "        self.augment_transform = augment_transform\n",
        "        self.is_train = is_train\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        \n",
        "        # Load images and labels\n",
        "        im1 = Image.open(os.path.join(self.data_dir, 'im1', img_name)).convert('RGB')\n",
        "        im2 = Image.open(os.path.join(self.data_dir, 'im2', img_name)).convert('RGB')\n",
        "        label1 = Image.open(os.path.join(self.data_dir, 'label1', img_name)).convert('L')\n",
        "        label2 = Image.open(os.path.join(self.data_dir, 'label2', img_name)).convert('L')\n",
        "        \n",
        "        # Apply augmentations\n",
        "        if self.is_train and self.augment_transform and random.random() > 0.5:\n",
        "            seed = random.randint(0, 2**32)\n",
        "            for img in [im1, im2, label1, label2]:\n",
        "                random.seed(seed)\n",
        "                torch.manual_seed(seed)\n",
        "                img = self.augment_transform(img)\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            im1 = self.transform(im1)\n",
        "            im2 = self.transform(im2)\n",
        "            label_transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            label1 = label_transform(label1)\n",
        "            label2 = label_transform(label2)\n",
        "        \n",
        "        # Convert labels to classes (0, 128, 255) -> (0, 1, 2)\n",
        "        label1 = (label1 * 255).long()\n",
        "        label2 = (label2 * 255).long()\n",
        "        \n",
        "        label1_new = torch.zeros_like(label1)\n",
        "        label2_new = torch.zeros_like(label2)\n",
        "        label1_new[label1 == 128] = 1\n",
        "        label1_new[label1 == 255] = 2\n",
        "        label2_new[label2 == 128] = 1\n",
        "        label2_new[label2 == 255] = 2\n",
        "        \n",
        "        return {\n",
        "            'im1': im1, 'im2': im2,\n",
        "            'label1': label1_new.squeeze(0), 'label2': label2_new.squeeze(0),\n",
        "            'filename': img_name\n",
        "        }\n",
        "\n",
        "class DualInputUNet(nn.Module):\n",
        "    def __init__(self, in_channels=6, out_channels=3, features=[64, 128, 256, 512]):\n",
        "        super(DualInputUNet, self).__init__()\n",
        "        \n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder1 = nn.ModuleList()\n",
        "        self.decoder2 = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Encoder\n",
        "        for feature in features:\n",
        "            self.encoder.append(self._conv_block(in_channels, feature))\n",
        "            in_channels = feature\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = self._conv_block(features[-1], features[-1] * 2)\n",
        "        \n",
        "        # Decoders\n",
        "        for feature in reversed(features):\n",
        "            self.decoder1.append(nn.ConvTranspose2d(feature * 2, feature, 2, 2))\n",
        "            self.decoder1.append(self._conv_block(feature * 2, feature))\n",
        "            self.decoder2.append(nn.ConvTranspose2d(feature * 2, feature, 2, 2))\n",
        "            self.decoder2.append(self._conv_block(feature * 2, feature))\n",
        "        \n",
        "        self.final_conv1 = nn.Conv2d(features[0], out_channels, 1)\n",
        "        self.final_conv2 = nn.Conv2d(features[0], out_channels, 1)\n",
        "        self.dropout = nn.Dropout2d(0.1)\n",
        "        \n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        \n",
        "        # Encoder\n",
        "        skip_connections = []\n",
        "        for encoder in self.encoder:\n",
        "            x = encoder(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "        \n",
        "        x = self.bottleneck(x)\n",
        "        x = self.dropout(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        \n",
        "        # Decoder 1\n",
        "        x1_dec = x\n",
        "        for idx in range(0, len(self.decoder1), 2):\n",
        "            x1_dec = self.decoder1[idx](x1_dec)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "            if x1_dec.shape != skip_connection.shape:\n",
        "                x1_dec = torch.nn.functional.interpolate(x1_dec, size=skip_connection.shape[2:], mode='bilinear', align_corners=False)\n",
        "            concat_skip = torch.cat((skip_connection, x1_dec), dim=1)\n",
        "            x1_dec = self.decoder1[idx + 1](concat_skip)\n",
        "        \n",
        "        # Decoder 2\n",
        "        x2_dec = x\n",
        "        for idx in range(0, len(self.decoder2), 2):\n",
        "            x2_dec = self.decoder2[idx](x2_dec)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "            if x2_dec.shape != skip_connection.shape:\n",
        "                x2_dec = torch.nn.functional.interpolate(x2_dec, size=skip_connection.shape[2:], mode='bilinear', align_corners=False)\n",
        "            concat_skip = torch.cat((skip_connection, x2_dec), dim=1)\n",
        "            x2_dec = self.decoder2[idx + 1](concat_skip)\n",
        "        \n",
        "        return self.final_conv1(x1_dec), self.final_conv2(x2_dec)\n",
        "\n",
        "print(\"âœ… Dataset class and model architecture defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration optimized for T4 GPU\n",
        "def get_t4_config():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 8\n",
        "    batch_size = 8 if gpu_memory >= 15 else 4 if gpu_memory >= 8 else 2\n",
        "    \n",
        "    return {\n",
        "        'batch_size': batch_size,\n",
        "        'num_workers': 2,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 50,\n",
        "        'patience': 10,\n",
        "        'mixed_precision': True,\n",
        "    }\n",
        "\n",
        "config = get_t4_config()\n",
        "print(f\"ðŸŽ¯ T4 GPU Configuration: {config}\")\n",
        "\n",
        "# Data transforms\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "])\n",
        "\n",
        "# Helper functions\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "def calculate_iou(pred, target, num_classes=3):\n",
        "    pred_np = pred.cpu().numpy().flatten()\n",
        "    target_np = target.cpu().numpy().flatten()\n",
        "    ious = []\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred_np == cls)\n",
        "        target_cls = (target_np == cls)\n",
        "        intersection = np.logical_and(pred_cls, target_cls).sum()\n",
        "        union = np.logical_or(pred_cls, target_cls).sum()\n",
        "        iou = intersection / union if union > 0 else 1.0\n",
        "        ious.append(iou)\n",
        "    return np.mean(ious)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, best_iou, filepath):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'best_iou': best_iou,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    torch.save(checkpoint, filepath)\n",
        "\n",
        "print(\"âœ… Training utilities ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data and initialize model\n",
        "train_files = sorted([f for f in os.listdir('/content/train/im1') if f.endswith('.png')])\n",
        "test_files = sorted([f for f in os.listdir('/content/test/im1') if f.endswith('.png')])\n",
        "\n",
        "print(f\"ðŸ“Š Dataset: {len(train_files)} train, {len(test_files)} test images\")\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = DualInputDataset('/content/train', train_files, base_transform, augment_transform, True)\n",
        "test_dataset = DualInputDataset('/content/test', test_files, base_transform, None, False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, \n",
        "                         num_workers=config['num_workers'], pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, \n",
        "                        num_workers=config['num_workers'], pin_memory=True)\n",
        "\n",
        "# Initialize model\n",
        "model = DualInputUNet(in_channels=6, out_channels=3).to(device)\n",
        "criterion = FocalLoss(alpha=1, gamma=2)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10)\n",
        "scaler = GradScaler() if config['mixed_precision'] and device.type == 'cuda' else None\n",
        "\n",
        "# Model info\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"ðŸ§  Model: {total_params:,} parameters (~{total_params*4/1024**2:.1f} MB)\")\n",
        "print(\"âœ… Ready to start training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main Training Loop\n",
        "def train_model():\n",
        "    best_iou = 0.0\n",
        "    patience_counter = 0\n",
        "    train_losses, val_losses, val_ious = [], [], []\n",
        "    \n",
        "    print(\"ðŸš€ Starting Training...\")\n",
        "    print(f\"Device: {device} | Batch Size: {config['batch_size']} | Epochs: {config['num_epochs']}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(config['num_epochs']):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Train]')\n",
        "        \n",
        "        for batch in train_pbar:\n",
        "            im1, im2 = batch['im1'].to(device), batch['im2'].to(device)\n",
        "            label1, label2 = batch['label1'].to(device), batch['label2'].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if scaler:  # Mixed precision\n",
        "                with autocast():\n",
        "                    out1, out2 = model(im1, im2)\n",
        "                    loss = criterion(out1, label1) + criterion(out2, label2)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:  # Regular precision\n",
        "                out1, out2 = model(im1, im2)\n",
        "                loss = criterion(out1, label1) + criterion(out2, label2)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            train_pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'LR': f'{scheduler.get_last_lr()[0]:.6f}',\n",
        "                'GPU': f'{torch.cuda.memory_allocated()/1024**3:.1f}GB' if torch.cuda.is_available() else 'N/A'\n",
        "            })\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(epoch_loss)\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_ious = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Val]')\n",
        "            for batch in val_pbar:\n",
        "                im1, im2 = batch['im1'].to(device), batch['im2'].to(device)\n",
        "                label1, label2 = batch['label1'].to(device), batch['label2'].to(device)\n",
        "                \n",
        "                if scaler:\n",
        "                    with autocast():\n",
        "                        out1, out2 = model(im1, im2)\n",
        "                        loss = criterion(out1, label1) + criterion(out2, label2)\n",
        "                else:\n",
        "                    out1, out2 = model(im1, im2)\n",
        "                    loss = criterion(out1, label1) + criterion(out2, label2)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                \n",
        "                # Calculate IoU\n",
        "                pred1 = torch.argmax(out1, dim=1)\n",
        "                pred2 = torch.argmax(out2, dim=1)\n",
        "                iou1 = calculate_iou(pred1, label1)\n",
        "                iou2 = calculate_iou(pred2, label2)\n",
        "                avg_iou = (iou1 + iou2) / 2\n",
        "                all_ious.append(avg_iou)\n",
        "                \n",
        "                val_pbar.set_postfix({'Loss': f'{loss.item():.4f}', 'IoU': f'{avg_iou:.4f}'})\n",
        "        \n",
        "        epoch_val_loss = val_loss / len(test_loader)\n",
        "        epoch_val_iou = np.mean(all_ious)\n",
        "        \n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_ious.append(epoch_val_iou)\n",
        "        \n",
        "        # Print epoch results\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f'\\\\nEpoch [{epoch+1}/{config[\"num_epochs\"]}] - Time: {elapsed/60:.1f}min')\n",
        "        print(f'Train Loss: {epoch_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val IoU: {epoch_val_iou:.4f}')\n",
        "        \n",
        "        # Save best model\n",
        "        if epoch_val_iou > best_iou:\n",
        "            best_iou = epoch_val_iou\n",
        "            patience_counter = 0\n",
        "            save_checkpoint(model, optimizer, epoch, best_iou, \n",
        "                          '/content/drive/MyDrive/geospatial_segmentation/models/best_model.pth')\n",
        "            print(f'ðŸŽ‰ New best model saved! IoU: {best_iou:.4f}')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        \n",
        "        # Early stopping\n",
        "        if patience_counter >= config['patience']:\n",
        "            print(f'â¹ï¸ Early stopping after {config[\"patience\"]} epochs without improvement')\n",
        "            break\n",
        "        \n",
        "        # Plot progress every 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.plot(train_losses, label='Train Loss')\n",
        "            plt.plot(val_losses, label='Val Loss')\n",
        "            plt.title('Loss')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            \n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.plot(val_ious, label='Val IoU', color='green')\n",
        "            plt.title('Validation IoU')\n",
        "            plt.grid(True)\n",
        "            \n",
        "            plt.subplot(1, 3, 3)\n",
        "            gpu_mem = torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0\n",
        "            plt.bar(['GPU Memory'], [gpu_mem], color='orange')\n",
        "            plt.title(f'GPU Memory: {gpu_mem:.1f}GB')\n",
        "            plt.ylim(0, 16)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        \n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        # Clear GPU cache\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    # Training completed\n",
        "    total_time = time.time() - start_time\n",
        "    print(f'\\\\nðŸŽ‰ Training completed in {total_time/3600:.2f} hours')\n",
        "    print(f'Best validation IoU: {best_iou:.4f}')\n",
        "    \n",
        "    # Save final model and history\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/geospatial_segmentation/models/final_model.pth')\n",
        "    \n",
        "    history = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'val_ious': val_ious,\n",
        "        'best_iou': best_iou,\n",
        "        'total_time_hours': total_time / 3600,\n",
        "        'config': config\n",
        "    }\n",
        "    \n",
        "    with open('/content/drive/MyDrive/geospatial_segmentation/logs/training_history.json', 'w') as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "    \n",
        "    return history\n",
        "\n",
        "# Start Training\n",
        "print(\"ðŸš€ Starting full dataset training on T4 GPU...\")\n",
        "print(\"This will take several hours. Progress will be saved to Google Drive.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "training_history = train_model()\n",
        "\n",
        "print(\"\\\\nðŸŽ‰ Training completed successfully!\")\n",
        "print(\"\\\\nðŸ“ Files saved to Google Drive:\")\n",
        "print(\"- best_model.pth (best performing model)\")\n",
        "print(\"- final_model.pth (final model state)\")\n",
        "print(\"- training_history.json (complete training logs)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Model Evaluation and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model and evaluate\n",
        "def load_and_evaluate():\n",
        "    # Load best model\n",
        "    checkpoint_path = '/content/drive/MyDrive/geospatial_segmentation/models/best_model.pth'\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        eval_model = DualInputUNet(in_channels=6, out_channels=3).to(device)\n",
        "        eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        eval_model.eval()\n",
        "        print(f\"âœ… Best model loaded (Epoch {checkpoint['epoch']}, IoU: {checkpoint['best_iou']:.4f})\")\n",
        "    else:\n",
        "        eval_model = model\n",
        "        print(\"âš ï¸ Using current model for evaluation\")\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    eval_model.eval()\n",
        "    all_ious = []\n",
        "    sample_results = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            if i >= 3:  # Only evaluate first few batches for demo\n",
        "                break\n",
        "                \n",
        "            im1, im2 = batch['im1'].to(device), batch['im2'].to(device)\n",
        "            label1, label2 = batch['label1'].to(device), batch['label2'].to(device)\n",
        "            \n",
        "            out1, out2 = eval_model(im1, im2)\n",
        "            pred1 = torch.argmax(out1, dim=1)\n",
        "            pred2 = torch.argmax(out2, dim=1)\n",
        "            \n",
        "            # Calculate IoU for this batch\n",
        "            for j in range(im1.size(0)):\n",
        "                iou1 = calculate_iou(pred1[j:j+1], label1[j:j+1])\n",
        "                iou2 = calculate_iou(pred2[j:j+1], label2[j:j+1])\n",
        "                avg_iou = (iou1 + iou2) / 2\n",
        "                all_ious.append(avg_iou)\n",
        "                \n",
        "                # Save sample for visualization\n",
        "                if len(sample_results) < 3:\n",
        "                    sample_results.append({\n",
        "                        'filename': batch['filename'][j],\n",
        "                        'im1': im1[j].cpu(),\n",
        "                        'im2': im2[j].cpu(),\n",
        "                        'label1': label1[j].cpu(),\n",
        "                        'label2': label2[j].cpu(),\n",
        "                        'pred1': pred1[j].cpu(),\n",
        "                        'pred2': pred2[j].cpu(),\n",
        "                        'iou': avg_iou\n",
        "                    })\n",
        "    \n",
        "    print(f\"ðŸ“Š Evaluation Results:\")\n",
        "    print(f\"Mean IoU: {np.mean(all_ious):.4f} Â± {np.std(all_ious):.4f}\")\n",
        "    \n",
        "    # Visualize sample results\n",
        "    for idx, sample in enumerate(sample_results):\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        \n",
        "        # Denormalize images for display\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        im1_denorm = torch.clamp(sample['im1'] * std + mean, 0, 1)\n",
        "        im2_denorm = torch.clamp(sample['im2'] * std + mean, 0, 1)\n",
        "        \n",
        "        # Plot images\n",
        "        axes[0, 0].imshow(im1_denorm.permute(1, 2, 0))\n",
        "        axes[0, 0].set_title('Input Image 1')\n",
        "        axes[0, 0].axis('off')\n",
        "        \n",
        "        axes[0, 1].imshow(im2_denorm.permute(1, 2, 0))\n",
        "        axes[0, 1].set_title('Input Image 2')\n",
        "        axes[0, 1].axis('off')\n",
        "        \n",
        "        # Plot ground truth\n",
        "        cmap = plt.cm.get_cmap('viridis', 3)\n",
        "        axes[0, 2].imshow(sample['label1'], cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[0, 2].set_title('Ground Truth 1')\n",
        "        axes[0, 2].axis('off')\n",
        "        \n",
        "        axes[0, 3].imshow(sample['label2'], cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[0, 3].set_title('Ground Truth 2')\n",
        "        axes[0, 3].axis('off')\n",
        "        \n",
        "        # Plot predictions\n",
        "        axes[1, 0].imshow(sample['pred1'], cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[1, 0].set_title('Prediction 1')\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        axes[1, 1].imshow(sample['pred2'], cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[1, 1].set_title('Prediction 2')\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        # Add colorbar and metrics\n",
        "        cbar = plt.colorbar(plt.cm.ScalarMappable(cmap=cmap), ax=axes[1, 2], ticks=[0, 1, 2])\n",
        "        cbar.set_ticklabels(['Background', 'Class 1', 'Class 2'])\n",
        "        axes[1, 2].axis('off')\n",
        "        \n",
        "        axes[1, 3].text(0.1, 0.5, f\"IoU: {sample['iou']:.4f}\", fontsize=14, \n",
        "                       verticalalignment='center', transform=axes[1, 3].transAxes)\n",
        "        axes[1, 3].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Sample {idx+1}: {sample[\"filename\"]}', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'/content/drive/MyDrive/geospatial_segmentation/logs/sample_{idx+1}.png', \n",
        "                   dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    \n",
        "    return eval_model\n",
        "\n",
        "# Run evaluation\n",
        "print(\"ðŸ” Evaluating trained model...\")\n",
        "eval_model = load_and_evaluate()\n",
        "\n",
        "# Inference function for new images\n",
        "def predict_new_images(model, im1_path, im2_path):\n",
        "    \"\"\"Predict on new image pairs\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    im1 = Image.open(im1_path).convert('RGB')\n",
        "    im2 = Image.open(im2_path).convert('RGB')\n",
        "    \n",
        "    im1_tensor = base_transform(im1).unsqueeze(0).to(device)\n",
        "    im2_tensor = base_transform(im2).unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        out1, out2 = model(im1_tensor, im2_tensor)\n",
        "        pred1 = torch.argmax(out1, dim=1).squeeze().cpu().numpy()\n",
        "        pred2 = torch.argmax(out2, dim=1).squeeze().cpu().numpy()\n",
        "    \n",
        "    return pred1, pred2, im1, im2\n",
        "\n",
        "print(\"âœ… Evaluation completed!\")\n",
        "print(\"ðŸ”® Use predict_new_images(eval_model, 'path/to/im1.png', 'path/to/im2.png') for inference on new images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ Training Summary\n",
        "\n",
        "### ðŸŽ¯ What was accomplished:\n",
        "- âœ… Trained a dual-input U-Net model on the complete dataset (2968 train + 1694 test images)\n",
        "- âœ… Optimized for Google Colab T4 GPU with mixed precision training\n",
        "- âœ… Implemented advanced data augmentation and Focal Loss for class imbalance\n",
        "- âœ… Real-time training monitoring with progress visualization\n",
        "- âœ… Automatic model checkpointing to Google Drive\n",
        "- âœ… Comprehensive evaluation with IoU metrics\n",
        "\n",
        "### ðŸ“ Output Files (saved to Google Drive):\n",
        "- `best_model.pth` - Best performing model checkpoint\n",
        "- `final_model.pth` - Final model weights  \n",
        "- `training_history.json` - Complete training logs and metrics\n",
        "- `sample_*.png` - Sample prediction visualizations\n",
        "\n",
        "### ðŸš€ Next Steps:\n",
        "1. **Fine-tuning**: Adjust hyperparameters for better performance\n",
        "2. **Deployment**: Convert to ONNX/TensorRT for faster inference\n",
        "3. **Analysis**: Study failure cases and improve data quality\n",
        "4. **Enhancement**: Try different architectures (DeepLab, Mask R-CNN)\n",
        "5. **Post-processing**: Add CRF or other refinement techniques\n",
        "\n",
        "### ðŸ’¡ Usage:\n",
        "- Use `predict_new_images(eval_model, 'im1_path', 'im2_path')` for inference\n",
        "- Models are automatically saved to your Google Drive\n",
        "- Training can be resumed from checkpoints if interrupted\n",
        "\n",
        "**Training optimized for T4 GPU with automatic batch size selection and memory management.**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
